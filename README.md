# CLIP Pretraining - Fashion Dataset

To get started:
- Read and run pull_images.ipynb to download images, should be ~600MB for seed 123 and 10% fraction
- Read and run Fashion_Model.ipynb to benchmark and use CLIP to extract tensors for training classification models
  
